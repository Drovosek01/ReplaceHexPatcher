# Тестирование функциональности

Утилита состоит из нескольких частей - основа/ядро и "обертки". Тестировать необходимо и то и другое. "Обертки" есть тоже 2х типов - CMD-код и Powershell-код. Для кода на CMD, вероятно нет никаких фреймворков и инструментов тестирования, так что там, наверное, только выводить лог работы функций через `echo` в окно терминала (что я и делал при тестировании своего кода).

Для Powershell есть как минимум 1 фреймворк для написания тестов - Pester (https://pester.dev/ | https://github.com/pester/Pester)

Но в данном проекте, пока что, не используются никакие фреймворки и самодельные тесты. Я тестирую различные варианты выполнения кода (использования инструмента) вручную.

Powershell-версия "обертки", которая представляет из себя парсер шаблона с выполнением инструкций из этого шаблона, получилась слишком громоздкая, потому что я хотел писал его после написания CMD-версии в которой разбиение функционала кода на разные файлы

Возможно позже займусь написанием тестов позже, но добавление функционала описанного в TODO-листе и улучшение читабельности кода в этом проекте для меня более важные вещи.

---

И так тестирование производится вручную. Вы можете в шаблон добавить необходимую вам информацию в необходимом вам виде, выполнить шаблон и проверить что будет.

Например, можно добавить в секцию для блокировки файлов фаерволом как прямые пути, так и пути с звездочкой на конце. Как существующие, так и несуществующие пути и сравнить какие правила были в фаерволе до выполнения шаблона и после. Аналогично и с другими секциями

Но вот с алгоритмом поиска и замены байт ситуация немного иная.

---

Существует множество вариантов поиска и замены байт:
- Конвертировать все байт файла в 1 большую строку и выполнять поиск и замену по этой большой строке, а потом строку конвертировать в байты файла
- Разбить файл на части и выполнять поиск и замену по частям
- Загрузить весь файл в память и работать с ним в памяти, а после замены байт выгрузить на накопитель

и т.д.

Естественно нам необходим вариант, при котором замена байт будет происходить максимально быстро и без ошибок (то есть будут заменены только те байты, которые мы указали).

Т.к. существует ChatGPT и другие GPT - можно поспрашивать его сгенерировать различные алгоритмы для поиска и замены байт на Powershell и многие сгенерированные им функции даже будут работать и работать правдоподобно на первый взгляд.

Но первый взгляд может быть обманчивым.

При тестировании новых алгоритмов поиска и замены байт всегда необходимо проверять результат работы алгоритма с результатом ручной замены байт в hex-редакторе (например с помощью [010 Editor](https://www.sweetscape.com/download/010editor/)). То есть для подопытного файла необходимо создать 2 копии. В первой копии необходимо сделать поиск и замену байт используя 010 Editor. Во второй копии поиск и замену тех же байт необходимо сделать используя скрипт с новым алгоритмом. Потом сравнить хэш суммы обеих копий файлов и если они одинаковы - значит алгоритм отработал верно и заменил все байты верно. Только после этого можно сравнивать временные показатели быстродействия алгоритма.

Здесь тоже есть нюанс. Некоторые алгоритмы могут казаться безупречными на первом пробном тестировании, но чтобы быть максимально уверенным, необходимо проверить поиск и замену таких последовательностей байт:
1. Какой-нибудь последовательности 16 байт взятой примерно из середины файла
2. Какой-нибудь последовательности 3 байт, которая встречается очень часто (более 10 000 раз) в файле
3. Последовательности байт в самом конце файла
4. Последовательности байт в самом начале файла
5. Последовательности байт который находятся на границах буфера, если в алгоритме файл читается частями с определенным буфером

Также не стоит забывать, что для тестов алгоритма лучше взять ощутимый (не маленького размера) файл, который весит более 100 МБ.

Это важно, потому что мне несколько раз ChatGPT выдавал код, который работал супер быстро (с использованием буфера), но при этом помимо указанных паттернов заменял и другие байты.

---

Для таких тестов алгоритмов (стратегий) поиска + замены байт я создал отдельную папку [search strategies](../core/search%20strategies/) в которой будут приводится примеры рабочих алгоритмов. ТОЛЬКО РАБОЧИХ АЛГОРИТМОВ/СТРАТЕГИЙ. Разница между ними должна быть только в скорости выполнения. Там будут располагаться файлы с структурой как у [ReplaceHexBytesAll.ps1](../core/ReplaceHexBytesAll.ps1), но с вырезанным "шумом", то есть без логики проверки прав администратора, снятия атрибутов "Только чтение", создания бэкапов. В файлах с стратегиями/алгоритмами должен быть только конвертер hex-паттернов передаваемых как аргументы и их применение к файлу и сопутствующий код без дополнительных проверок доступа и т.д., чтобы не засорять код и работать только на алгоритмом/стратегией поиска байт.

На данный момент существуют такие алгоритмы/стратегии:

1. v1 - первая реализация поиска и замены байт. Была с помощью запросов к ChatGPT 4 (free) и доработана вручную. Работает на основе .NET-функции `[System.IO.File]::ReadAllBytes($targetPath)`, что приводит копирование всего файла в память (ОЗУ). Несмотря на то, что файл находился в ОЗУ замена большого количества (примерно 30000 участков в файле размером ~120 МБ) коротких паттернов по 3 байта длилось очень долго, поэтому решил найти более быстрые способы поиска
2. v2 - полное портирование алгоритма поиска и замены байт из этой https://github.com/jjxtra/HexAndReplace/blob/d6dc05b6eef242149bcbb876a1f923f4311fd08b/BinaryReplacer.cs утилиты. Несмотря на то, что скомпилированный .exe этой утилиты ищет паттерны чертовски быстро, но мой портированный на Powershell вариант работал в некоторых случая медленнее, чем алгоритм v1. Я решил, что это из-за того, что все байт перебираются последовательно и можно это оптимизировать заменив перебор на поиск через `IndexOf()`
3. v3 - комбинированный вариант на основе v2 и v1. За основу взят v2, но вместо последовательного перебора и сравнения всех байт каждый буферизированный участок файла преобразуется в массив байт и происходит поиск через `IndexOf()` по массиву. Это дало ощутимый прирост к скорости. Хоть и кажется что `IndexOf()` делает последовательный перебор элементов массива (в данном случае перебор байт), но, вероятно, под капотом там есть какие-то оптимизации поиска, что делает его намного быстрее обычного последовательного перебора.
4. v3.1 - тот же алгоритм v3, но с использованием подстановочных знаков wildcards в паттернах поиска и замены 

Разумеется в скрипте-патчере используется самый быстрый алгоритм/стратегия для поиска и замены байт. На данный момент это v3.