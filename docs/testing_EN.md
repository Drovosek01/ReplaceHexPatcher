# Testing functionality

The utility consists of several parts - the base/core and the "wrappers". It is necessary to test both. There are also 2 types of "wrappers" - CMD code and Powershell code. For the CMD code, there are probably no frameworks and testing tools, so there is probably only output the log of the functions through the `echo` to the terminal window (which I did when testing my code).

There is at least 1 framework for writing tests for Powershell - Pester (https://pester.dev/ | https://github.com/pester/Pester)

But in this project, so far, no frameworks and homemade tests are used. I am testing various code execution options (using the tool) manually.

The Powershell version of the wrapper, which is a template parser with instructions from this template, turned out to be too cumbersome, because I wanted to write it after writing the CMD version in which the code functionality is divided into different files

Maybe I'll start writing tests later, but adding the functionality described in the TODO list and improving the readability of the code in this project are more important things for me.

---

And so the testing is done manually. You can add the information you need to the template in the form you need, execute the template and check what will happen.

For example, you can add both direct paths and paths with an asterisk at the end to the firewall file blocking section. Both existing and non-existing paths and compare which rules were in the firewall before and after the template execution. It is the same with other sections

But with the byte search and replace algorithm, the situation is a little different.

---

There are many options for finding and replacing bytes:
- Convert all bytes of the file into 1 large string and perform search and replace on this large string, and then convert the string to bytes of the file
- Split the file into parts and perform search and replace in parts
- Load the entire file into memory and work with it in memory, and after replacing the bytes, upload it to the drive

etc.

Naturally, we need an option in which byte replacement will occur as quickly as possible and without errors. (that is, only the bytes that we specified will be replaced).

Since there is ChatGPT and other GPT, you can ask him to generate various algorithms for finding and replacing bytes on Powershell, and many of the functions generated by him will even work and work plausibly at first glance.

At first glance, it can be deceptive.

When testing new byte search and replacement algorithms, it is always necessary to check the result of the algorithm with the result of manual byte replacement in the hex editor (for example, using [010 Editor](https://www.sweetscape.com/download/010editor/)). That is, 2 copies must be created for the experimental file. In the first copy, you need to search and replace bytes using 010 Editor. In the second copy, the search and replacement of the same bytes must be done using a script with a new algorithm. Then compare the hash of the sum of both copies of the files and if they are the same, then the algorithm worked correctly and replaced all the bytes correctly. Only after that, you can compare the time performance of the algorithm.

There is a nuance here too. Some algorithms may seem flawless on the first trial test, but to be as sure as possible, it is necessary to check the search and replacement of such byte sequences:
1. Some sequence of 16 bytes taken from about the middle of the file
2. Some sequence of 3 bytes that occurs very often (more than 10,000 times) in the file
3. Byte sequences at the very end of the file
4. Byte sequences at the very beginning of the file
5. Sequences of bytes that are located on the buffer boundaries, if in the algorithm the file is read in parts with a certain buffer

Also, do not forget that for algorithm tests it is better to take a tangible (not small) file that weighs more than 100 MB.

This is important because ChatGPT gave me code several times that worked super fast (using a buffer), but at the same time, in addition to the specified patterns, it replaced other bytes.

---

For such tests of algorithms (strategies) for searching + replacing bytes, I created a separate folder [search strategies](../core/search%20strategies/) which will provide examples of working algorithms. ONLY WORKING ALGORITHMS/STRATEGIES. The difference between them should be only in the speed of execution. There will be files with the same structure as [ReplaceHexBytesAll.ps1](../core/ReplaceHexBytesAll.ps1), but with the "noise" cut out, that is, without the logic of checking administrator rights, removing "Read-only" attributes, and creating backups. In files with strategies/algorithms, there should only be a converter of hex patterns passed as arguments and their application to the file and the accompanying code without additional access checks, etc., so as not to clog the code and work only on the byte search algorithm/strategy.

At the moment, there are such algorithms/strategies:

1. v1 is the first implementation of byte search and replace. It was created using requests to ChatGPT 4 (free) and modified manually. It works based on .NET functions `[System.IO.File]::ReadAllBytes($targetPath)`, which results in copying the entire file to memory (RAM). Despite the fact that the file was in RAM, replacing a large number (about 30,000 sections in a ~120 MB file) of short 3-byte patterns took a very long time, so I decided to find faster ways to search
2. v2 - complete porting of the byte search and replace algorithm from this https://github.com/jjxtra/HexAndReplace/blob/d6dc05b6eef242149bcbb876a1f923f4311fd08b/BinaryReplacer.cs utilities. Despite being compiled .The exe of this utility searches for patterns damn fast, but my version ported to Powershell worked in some cases slower than the v1 algorithm. I decided that this is due to the fact that all bytes are iterated sequentially and it can be optimized by replacing the iteration with a search using `IndexOf()`
3. v3 is a combined version based on v2 and v1. V2 is taken as a basis, but instead of sequentially iterating through and comparing all bytes, each buffered section of the file is converted into an array of bytes and a search is performed through the `IndexOf()` array. This gave a noticeable increase in speed. Although it seems that `IndexOf()` does a sequential iteration of the array elements (in this case, byte iteration), but probably there are some search optimizations under the hood, which makes it much faster than a regular sequential iteration.
4. v3.1 - the same v3 algorithm, but using wildcards wildcards in search and replace patterns

Of course, the patcher script uses the fastest algorithm/strategy to find and replace bytes. At the moment it's v3.